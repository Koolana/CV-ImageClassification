# CV-ImageClassification

## Code requirements
* numpy: pip3 install numpy
* opencv: pip3 install opencv-python
* torch: pip3 install torch
* glob: pip3 install glob

__glob__: позволяет нам легко находить пути к данным внутри вложенных папок

__cv2__: используется в качестве библиотеки обработки изображений для чтения и предварительной обработки изображений

__numpy__: используется для матричных операций

__torch__: используется для создания классов Dataset и Dataloader, а также для преобразования данных в тензоры.

## Model description
Обучение модели глубокого обучения требует от нас преобразования данных в формат, который может быть обработан моделью. 

Нейронные сети могут быть построены с использованием пакета torch.nn.
torch.nn зависит от autograd в определении моделей и их дифференцировании. nn.Module содержит слои и метод forward(input), который возвращает output.
Типичная процедура обучения для нейронной сети следующая:

1. Определение нейронной сети, которая имеет некоторые изучаемые параметры (или веса);
2. Итерация по набору входных данных;
3. Обработка ввода через сеть;
4. Рассчет потери (насколько далеки результаты от правильных);
5. Распространение градиентов обратно на параметры сети;
6. Обновление весов сети, как правило, используя простое правило обновления:
weight = weight - learning_rate * gradient.

Использована нейронная сеть для приема 3-канального изображения.

__Добавить сведения о нейронной сети__

## Dataset
Структура папок выглядит следующим образом. У нас есть папка Project, которая содержит код main.py и код model.py, и папка под названием "dataset". Эта папка под названием "dataset" - это папка dataset, которая содержит 4 вложенные папки под названиями Soup, Dessert, Meat и Bread.

[Ссылка на набор данных здесь](https://drive.google.com/drive/folders/1fkSZmSQo_W6Jz3Jb5R0bWwQKKH1Pn2x0?usp=sharing)

## Experiments
### File "main.py"
Создание пользовательского набора данных и загрузчика данных в Pytorch подробно описано в [документации](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).

Мы определяем функцию init для инициализации наших переменных. Переменная self.imgs_path содержит базовый путь к нашей папке "dataset".

Мы создали список со всеми нашими данными, мы начинаем кодировать функцию для __len__(), которая является обязательным для объекта Torch Dataset.

Размер нашего набора данных - это просто количество отдельных изображений, которые у нас есть, которое можно получить через длину списка self.data. (Torch внутренне использует эту функцию для понимания размера набора данных в своем dataloader, чтобы вызвать функцию __getitem__() с индексом в пределах этого размера набора данных). Для обучения модели мы все изображения преобразуем к размерам 128х128.

Поскольку мы создали набор данных, мы можем использовать этот класс в загрузчике данных torch для перебора этих данных во время обучения.

### File "model.py"
В данном файле представлена модель созданной сверточной сети. Пройдемся по каждому шагу.

Conv2d: Слой 2D свертки (например, пространственная свертка над изображениями). Этот слой создает ядро свертки, которое свертывается со входом слоя для получения тензора выходов. nn.Conv2d принимает 4D тензор: nSamples x nChannels x Height x Width.

MaxPool2d: Одна из проблем с картами объектов, созданными из сверточного слоя, заключается в том, что они слишком чувствительны к расположению объектов на изображении. Одним из решений для этого является понижающая выборка карты функций, и это именно то, что делает пул. Уменьшая количество функций, мы можем до некоторой степени избежать проблемы переоснащения. Это также снижает вычислительные затраты, связанные с обучением модели.

Linear: Слой Linear делает линейное преобразование входного тензора.

## Results
Для нашей модели получены следующие результаты на сгенерированной тестовой выборке:
(Пример, Точность).

Подробный отчет по модели представлен в файле программы Jupyter: *demo.ipynb*.

Jupyter: __Добавить: графики зависимости значений функции потерь и точности от номера эпохи (как для обучающей, так и для тестовой выборки), число неверных предсказаний для тестовой выборки, матрицу ошибок, несколько неправильно распознанных изображений (с указанием, какому классу изображение принадлежит и какой класс для изображения предсказан).__

Вывод примеров тренировочных данных:

<img width="581" alt="before" src="https://user-images.githubusercontent.com/90565598/149660026-05f4a6ff-9957-4417-98a1-d338929b7f40.png">

Вывод информации о модели:

<img width="358" alt="summary" src="https://user-images.githubusercontent.com/90565598/149660120-f15326a5-106a-45fb-a0e1-fa2f77e82acb.png">

График зависимости функции потерь от номера эпохи:

<img width="428" alt="loss" src="https://user-images.githubusercontent.com/90565598/149660161-7e644143-75c1-4a78-9c36-e4109a2fb0b2.png">

График зависимости точности от номера эпохи:

<img width="429" alt="accuracy" src="https://user-images.githubusercontent.com/90565598/149660013-11d7b5f6-7f73-4411-9146-a373afc67e8e.png">

Проверка наилучшей модели по картинкам:

<img width="619" alt="after" src="https://user-images.githubusercontent.com/90565598/149660214-94d359f3-2bde-4a08-8f59-4b78a4846e4c.png">

